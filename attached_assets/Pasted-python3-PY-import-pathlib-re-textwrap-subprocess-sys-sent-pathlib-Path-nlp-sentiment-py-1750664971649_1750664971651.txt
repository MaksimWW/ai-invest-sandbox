python3 - <<'PY'
import pathlib, re, textwrap, subprocess, sys
sent = pathlib.Path("nlp/sentiment.py")

# â”€â”€ ÑƒÐ´Ð°Ð»Ð¸Ñ‚ÑŒ Ð›Ð®Ð‘ÐžÐ™ ÑÑ‚Ð°Ñ€Ñ‹Ð¹ fetch_ru_news (ÐµÑÐ»Ð¸ Ð¾Ð½ ÐµÑÑ‚ÑŒ) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
txt = sent.read_text(encoding="utf-8")
txt = re.sub(
    r"\n\s*def\s+fetch_ru_news[\s\S]+?\n\s*return[^\n]*\n",  # Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½Ð¾ Ð½Ð°Ð´Ñ‘Ð¶Ð½Ð¾
    "\n",
    txt,
    count=1,
    flags=re.M,
)

# â”€â”€ Ð²ÑÑ‚Ð°Ð²Ð¸Ñ‚ÑŒ ÐŸÐžÐ›ÐÐ£Ð®, ÑÐ°Ð¼Ð¾Ð´Ð¾ÑÑ‚Ð°Ñ‚Ð¾Ñ‡Ð½ÑƒÑŽ Ð²ÐµÑ€ÑÐ¸ÑŽ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
new_code = textwrap.dedent("""
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ðŸš€ robust fetch_ru_news â€” ÑÐ¾Ð±Ð¸Ñ€Ð°ÐµÑ‚ ðŸ‡·ðŸ‡º RSS-Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð·Ð° N Ñ‡Ð°ÑÐ¾Ð²
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    from datetime import datetime, timedelta
    def fetch_ru_news(hours: int = 24) -> list[str]:
        \"\"\"Ð’Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ñ€ÑƒÑÑÐºÐ¾ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ðµ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¸ Ð·Ð° *hours* Ñ‡Ð°ÑÐ¾Ð².\"\"\"
        # âžŠ Ð¿Ñ‹Ñ‚Ð°ÐµÐ¼ÑÑ Ð½Ð°Ð¹Ñ‚Ð¸ ÑÐ¿Ð¸ÑÐ¾Ðº Ð»ÐµÐ½Ñ‚
        try:
            from nlp.news_feed import RSS_FEED_URLS as _FEEDS            # ÑÐ¾Ð²Ñ€ÐµÐ¼ÐµÐ½Ð½Ñ‹Ð¹ Ð²Ð°Ñ€Ð¸Ð°Ð½Ñ‚
        except ImportError:
            try:
                from nlp.news_rss_async import RSS_FEEDS as _DICT        # ÑÑ‚Ð°Ñ€Ñ‹Ð¹ ÑÐ»Ð¾Ð²Ð°Ñ€ÑŒ
                _FEEDS = list(_DICT.values())
            except ImportError:
                _FEEDS = []                                              # Ð½Ð¸Ñ‡ÐµÐ³Ð¾ Ð½Ðµ Ð½Ð°ÑˆÐ»Ð¸

        # âž‹ Ð±ÐµÑ€Ñ‘Ð¼ Ð¿Ð°Ñ€ÑÐµÑ€ RSS-Ð»ÐµÐ½Ñ‚Ñ‹
        try:
            from nlp.news_feed import _rss_query
        except ImportError:
            return []

        cutoff  = datetime.utcnow() - timedelta(hours=hours)
        titles: list[str] = []

        for url in _FEEDS:
            try:
                for art in _rss_query(url):
                    if art.get("dt") and art["dt"] >= cutoff and art.get("title"):
                        titles.append(art["title"].strip())
            except Exception:
                continue    # Ð¿Ð°Ð´Ð°ÑŽÑ‰Ð¸Ð¹ Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸Ðº Ð¿Ñ€Ð¾Ð¿ÑƒÑÐºÐ°ÐµÐ¼
        return titles
""")

sent.write_text(txt.rstrip() + "\n\n" + new_code + "\n", encoding="utf-8")
print("âœ“ sentiment.py: fetch_ru_news Ð¿ÐµÑ€ÐµÐ¿Ð¸ÑÐ°Ð½")

# â”€â”€ Ð±Ñ‹ÑÑ‚Ñ€Ñ‹Ð¹ smoke-Ñ‚ÐµÑÑ‚ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
from nlp.sentiment import fetch_ru_news
for h in (3, 6, 12):
    print(f"{h:>2} Ñ‡ â†’ {len(fetch_ru_news(h))} Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²ÐºÐ¾Ð²")

print("\npytest â€¦")
subprocess.run(["pytest", "-q", "-rs"], check=False)
PY