"""
news_feed.py  ‚Äì   –∞–≥—Ä–µ–≥–∞—Ç–æ—Ä –∞–Ω–≥–ª–æ—è–∑—ã—á–Ω—ã—Ö –Ω–æ–≤–æ—Å—Ç–µ–π
-------------------------------------------------
fetch_news(ticker: str, hours: int = 24) -> list[str]
"""
import os, datetime as dt, requests

NEWSAPI_KEY = os.getenv("NEWSAPI_KEY")

def _newsapi_query(q, from_dt):
    url = "https://newsapi.org/v2/everything"
    params = {
        "q"      : q,
        "language": "en",
        "sortBy" : "publishedAt",
        "from"   : from_dt.isoformat(timespec="seconds"),
        "apiKey" : NEWSAPI_KEY,
        "pageSize": 100,
    }
    r = requests.get(url, params=params, timeout=6)
    r.raise_for_status()
    return [a["title"] for a in r.json().get("articles", [])]

def _gdelt_query(q, from_dt):
    # GDELT 2.0 Events API —Å –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–º–∏ endpoints
    since = int(from_dt.timestamp())
    
    # –°–ø–∏—Å–æ–∫ –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã—Ö endpoints
    endpoints = [
        f"https://api.gdeltproject.org/api/v2/doc/docsearch?query={q}&filter=SourceCommonName:english&maxrecords=100&format=json&mode=ArtList&filter=PublishDate>{since}",
        f"https://api.gdeltproject.org/api/v2/doc/docsearchsearch?query={q}&filter=SourceCommonName:english&maxrecords=100&format=json&mode=ArtList&filter=PublishDate>{since}"
    ]
    
    for endpoint_idx, url in enumerate(endpoints, 1):
        endpoint_name = "docsearch" if "docsearch?" in url else "docsearchsearch"
        print(f"üåê –ü—Ä–æ–±—É–µ–º GDELT endpoint #{endpoint_idx} ({endpoint_name})...")
        
        # –ü–æ–ø—ã—Ç–∞–µ–º—Å—è –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è 2 —Ä–∞–∑–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ endpoint
        for attempt in range(2):
            try:
                print(f"üîÑ {endpoint_name} –ø–æ–ø—ã—Ç–∫–∞ {attempt + 1}/2...")
                r = requests.get(url, timeout=15)
                r.raise_for_status()
                
                data = r.json()
                articles = data.get("artList", [])
                print(f"‚úÖ GDELT ({endpoint_name}): –Ω–∞–π–¥–µ–Ω–æ {len(articles)} –Ω–æ–≤–æ—Å—Ç–µ–π")
                return [item["title"] for item in articles]
                
            except requests.exceptions.Timeout:
                print(f"‚è∞ {endpoint_name} —Ç–∞–π–º–∞—É—Ç –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
            except requests.exceptions.ConnectionError:
                print(f"üåê {endpoint_name} –ø—Ä–æ–±–ª–µ–º–∞ —Å–æ–µ–¥–∏–Ω–µ–Ω–∏—è –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}")
            except Exception as e:
                print(f"‚ùå {endpoint_name} –æ—à–∏–±–∫–∞ –Ω–∞ –ø–æ–ø—ã—Ç–∫–µ {attempt + 1}: {type(e).__name__}")
                
            if attempt < 1:  # –ù–µ –ø–æ—Å–ª–µ–¥–Ω—è—è –ø–æ–ø—ã—Ç–∫–∞ –¥–ª—è —ç—Ç–æ–≥–æ endpoint
                import time
                sleep_time = 2
                print(f"‚è≥ –ü–∞—É–∑–∞ {sleep_time} —Å–µ–∫ –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º...")
                time.sleep(sleep_time)
        
        print(f"‚ùå GDELT endpoint {endpoint_name} –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω")
    
    print("‚ùå –í—Å–µ GDELT endpoints –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –±–µ–∑ –Ω–µ–≥–æ")
    return []

def fetch_news(ticker: str, hours: int = 24) -> list[str]:
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –∞–Ω–≥–ª. –∑–∞–≥–æ–ª–æ–≤–∫–æ–≤ –∑–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ `hours` —á–∞—Å–æ–≤."""
    cutoff = dt.datetime.utcnow() - dt.timedelta(hours=hours)
    news = []
    
    # NewsAPI
    if NEWSAPI_KEY:
        print(f"üì∞ –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º NewsAPI –¥–ª—è {ticker}...")
        newsapi_results = _newsapi_query(ticker, cutoff)
        news += newsapi_results
        print(f"‚úÖ NewsAPI: –Ω–∞–π–¥–µ–Ω–æ {len(newsapi_results)} –Ω–æ–≤–æ—Å—Ç–µ–π")
    else:
        print("‚ö†Ô∏è NewsAPI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω (–Ω–µ—Ç NEWSAPI_KEY)")
    
    # GDELT
    gdelt_results = _gdelt_query(ticker, cutoff)
    news += gdelt_results
    
    print(f"üìä –ò—Ç–æ–≥–æ –¥–ª—è {ticker}: {len(news)} –Ω–æ–≤–æ—Å—Ç–µ–π (NewsAPI: {len(news) - len(gdelt_results)}, GDELT: {len(gdelt_results)})")
    return news