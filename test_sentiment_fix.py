
#!/usr/bin/env python
"""
–†–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç –Ω–æ–≤–æ–≥–æ –∫–æ–º–ø–æ–∑–∏—Ç–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è
"""

def test_contextual_sentiment():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –Ω–æ–≤—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä"""
    print("üß† –¢–ï–°–¢ –ö–û–ù–¢–ï–ö–°–¢–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê–¢–û–†–ê –ù–ê–°–¢–†–û–ï–ù–ò–ô")
    print("=" * 70)

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º —Ñ—É–Ω–∫—Ü–∏–∏
    try:
        from nlp.sentiment import classify_ru, classify_en, analyze_sentiment_trend, ContextualSentimentAnalyzer
        print("‚úÖ –ò–º–ø–æ—Ä—Ç –Ω–æ–≤—ã—Ö —Ñ—É–Ω–∫—Ü–∏–π —É—Å–ø–µ—à–µ–Ω")
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –∏–º–ø–æ—Ä—Ç–∞: {e}")
        return False

    # –¢–µ—Å—Ç—ã —Å —É—á–µ—Ç–æ–º –≤–µ–ª–∏—á–∏–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π
    magnitude_tests = [
        # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ —Å —á–∏—Å–ª–∞–º–∏
        ("–ê–∫—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 15% –ø–æ—Å–ª–µ –æ—Ç–ª–∏—á–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤", "positive"),
        ("–¶–µ–Ω–∞ –ø–æ–¥–Ω—è–ª–∞—Å—å –Ω–∞ 8.5% –±–ª–∞–≥–æ–¥–∞—Ä—è —Ö–æ—Ä–æ—à–∏–º –Ω–æ–≤–æ—Å—Ç—è–º", "positive"),
        ("Apple stock surged 12% on strong earnings", "positive"),
        
        # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–µ –±–µ–∑ —á–∏—Å–µ–ª, –Ω–æ —Å —Å–∏–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        ("–ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ —Ä–µ–∫–æ—Ä–¥–Ω—É—é –ø—Ä–∏–±—ã–ª—å", "positive"),
        ("–ê–∫—Ü–∏–∏ –≤–∑–ª–µ—Ç–µ–ª–∏ –ø–æ—Å–ª–µ breakthrough", "positive"),
        
        # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å —á–∏—Å–ª–∞–º–∏
        ("–°—Ç–æ–∏–º–æ—Å—Ç—å —É–ø–∞–ª–∞ –Ω–∞ 10% –∏–∑-–∑–∞ –ø–ª–æ—Ö–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π", "negative"),
        ("Tesla shares plummeted 7% after announcement", "negative"),
        
        # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–µ —Å —Å–∏–ª—å–Ω—ã–º–∏ —Å–ª–æ–≤–∞–º–∏
        ("–ü—Ä–æ–∏–∑–æ—à–µ–ª –æ–±–≤–∞–ª –∫–æ—Ç–∏—Ä–æ–≤–æ–∫ –∫–æ–º–ø–∞–Ω–∏–∏", "negative"),
        ("–ê–∫—Ü–∏–∏ –æ–±—Ä—É—à–∏–ª–∏—Å—å –ø–æ—Å–ª–µ –∫—Ä–∏–∑–∏—Å–∞", "negative"),
        
        # –ù–µ–π—Ç—Ä–∞–ª—å–Ω—ã–µ (–¥–∞–∂–µ –µ—Å–ª–∏ ML –≤–∏–¥–∏—Ç –Ω–µ–≥–∞—Ç–∏–≤)
        ("–¢–æ—Ä–≥–∏ –∑–∞–≤–µ—Ä—à–∏–ª–∏—Å—å –±–µ–∑ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –∏–∑–º–µ–Ω–µ–Ω–∏–π", "neutral"),
        ("–¶–µ–Ω–∞ –æ—Å—Ç–∞–ª–∞—Å—å —Å—Ç–∞–±–∏–ª—å–Ω–æ–π –Ω–∞ —É—Ä–æ–≤–Ω–µ 100 —Ä—É–±–ª–µ–π", "neutral"),
        ("Microsoft remained flat with 0.1% change", "neutral"),
        
        # –ú–∞–ª—ã–µ –∏–∑–º–µ–Ω–µ–Ω–∏—è (–¥–æ–ª–∂–Ω—ã –±—ã—Ç—å –Ω–µ–π—Ç—Ä–∞–ª—å–Ω—ã–º–∏)
        ("–ê–∫—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 0.5%", "neutral"),
        ("–¶–µ–Ω–∞ —Å–Ω–∏–∑–∏–ª–∞—Å—å –Ω–∞ 1%", "neutral"),
    ]

    print(f"\nüß™ –¢–µ—Å—Ç–∏—Ä—É–µ–º {len(magnitude_tests)} —Å–ª—É—á–∞–µ–≤ —Å —É—á–µ—Ç–æ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞:")
    print("-" * 70)

    correct = 0
    total = len(magnitude_tests)

    for i, (text, expected) in enumerate(magnitude_tests, 1):
        print(f"\nüìù –¢–µ—Å—Ç {i}: {text}")
        print(f"üéØ –û–∂–∏–¥–∞–µ–º: {expected}")

        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —è–∑—ã–∫ –∏ –≤—ã–∑—ã–≤–∞–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â—É—é —Ñ—É–Ω–∫—Ü–∏—é
        if any(russian_char in text for russian_char in "–∞–±–≤–≥–¥–µ—ë–∂–∑–∏–π–∫–ª–º–Ω–æ–ø—Ä—Å—Ç—É—Ñ—Ö—Ü—á—à—â—ä—ã—å—ç—é—è"):
            result = classify_ru(text)
        else:
            result = classify_en(text)

        print(f"‚úÖ –ü–æ–ª—É—á–∏–ª–∏: {result}")

        if result == expected:
            print("‚úÖ –ü–†–û–ô–î–ï–ù")
            correct += 1
        else:
            print("‚ùå –ü–†–û–í–ê–õ–ï–ù")

        print("-" * 50)

    # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã
    accuracy = (correct / total) * 100
    print(f"\nüìä –†–ï–ó–£–õ–¨–¢–ê–¢–´ –ö–û–ù–¢–ï–ö–°–¢–ù–û–ì–û –ê–ù–ê–õ–ò–ó–ê:")
    print(f"‚úÖ –ü—Ä–æ–π–¥–µ–Ω–æ: {correct}/{total}")
    print(f"üìà –¢–æ—á–Ω–æ—Å—Ç—å: {accuracy:.1f}%")

    return accuracy

def test_trend_analysis():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∞–Ω–∞–ª–∏–∑ —Ç—Ä–µ–Ω–¥–æ–≤"""
    print("\nüìà –¢–ï–°–¢ –ê–ù–ê–õ–ò–ó–ê –¢–†–ï–ù–î–û–í")
    print("=" * 50)
    
    from nlp.sentiment import analyze_sentiment_trend
    
    # –ü–æ–∑–∏—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥
    positive_news = [
        "–ê–∫—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 5%",
        "–ö–æ–º–ø–∞–Ω–∏—è –ø–æ–∫–∞–∑–∞–ª–∞ –æ—Ç–ª–∏—á–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã", 
        "–ü—Ä–∏–±—ã–ª—å –ø—Ä–µ–≤–∑–æ—à–ª–∞ –æ–∂–∏–¥–∞–Ω–∏—è"
    ]
    
    # –ù–µ–≥–∞—Ç–∏–≤–Ω—ã–π —Ç—Ä–µ–Ω–¥
    negative_news = [
        "–ê–∫—Ü–∏–∏ —É–ø–∞–ª–∏ –Ω–∞ 8%",
        "–ö–æ–º–ø–∞–Ω–∏—è –ø–æ–Ω–µ—Å–ª–∞ —É–±—ã—Ç–∫–∏",
        "–ü—Ä–æ–∏–∑–æ—à–µ–ª –æ–±–≤–∞–ª –∫–æ—Ç–∏—Ä–æ–≤–æ–∫"
    ]
    
    # –°–º–µ—à–∞–Ω–Ω—ã–π —Ç—Ä–µ–Ω–¥
    mixed_news = [
        "–ê–∫—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 3%",
        "–¶–µ–Ω–∞ —É–ø–∞–ª–∞ –Ω–∞ 2%",
        "–¢–æ—Ä–≥–∏ –ø—Ä–æ—à–ª–∏ —Å—Ç–∞–±–∏–ª—å–Ω–æ"
    ]
    
    test_cases = [
        (positive_news, "–ø–æ–∑–∏—Ç–∏–≤–Ω—ã–π"),
        (negative_news, "–Ω–µ–≥–∞—Ç–∏–≤–Ω—ã–π"), 
        (mixed_news, "—Å–º–µ—à–∞–Ω–Ω—ã–π")
    ]
    
    for news_list, expected_type in test_cases:
        result = analyze_sentiment_trend(news_list)
        print(f"\nüì∞ {expected_type.title()} —Ç—Ä–µ–Ω–¥:")
        print(f"   –°—Ä–µ–¥–Ω–µ–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏–µ: {result['trend']:.2f}")
        print(f"   –£–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å: {result['confidence']:.2f}")
        print(f"   –†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {result['distribution']}")

def test_magnitude_extraction():
    """–¢–µ—Å—Ç–∏—Ä—É–µ—Ç –∏–∑–≤–ª–µ—á–µ–Ω–∏–µ –≤–µ–ª–∏—á–∏–Ω—ã –∏–∑–º–µ–Ω–µ–Ω–∏–π"""
    print("\nüî¢ –¢–ï–°–¢ –ò–ó–í–õ–ï–ß–ï–ù–ò–Ø –í–ï–õ–ò–ß–ò–ù–´ –ò–ó–ú–ï–ù–ï–ù–ò–ô")
    print("=" * 50)
    
    from nlp.sentiment import ContextualSentimentAnalyzer
    analyzer = ContextualSentimentAnalyzer()
    
    test_texts = [
        "–ê–∫—Ü–∏–∏ –≤—ã—Ä–æ—Å–ª–∏ –Ω–∞ 15.5%",
        "–¶–µ–Ω–∞ —É–ø–∞–ª–∞ –Ω–∞ 8,2% –∑–∞ –¥–µ–Ω—å",
        "Apple stock surged 12% after earnings",
        "–ü—Ä–æ–∏–∑–æ—à–µ–ª —Ä–µ–∫–æ—Ä–¥–Ω—ã–π —Ä–æ—Å—Ç –±–µ–∑ —Ü–∏—Ñ—Ä",
        "–°—Ç–∞–±–∏–ª—å–Ω–∞—è —Ü–µ–Ω–∞ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π"
    ]
    
    for text in test_texts:
        magnitude = analyzer.extract_magnitude(text)
        print(f"\nüìù '{text}'")
        print(f"   –ß–∏—Å–ª–æ–≤–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ: {magnitude['numeric_value']}")
        print(f"   –°–∏–ª—å–Ω—ã–µ —Å–∏–≥–Ω–∞–ª—ã: {magnitude['has_strong_signals']}")
        print(f"   –ü–∞—Ç—Ç–µ—Ä–Ω—ã: {magnitude['magnitude_scores']}")

if __name__ == "__main__":
    print("üöÄ –ó–ê–ü–£–°–ö –†–ê–°–®–ò–†–ï–ù–ù–û–ì–û –¢–ï–°–¢–ò–†–û–í–ê–ù–ò–Ø")
    print("=" * 70)
    
    # –û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç
    accuracy = test_contextual_sentiment()
    
    # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ—Å—Ç—ã
    test_trend_analysis()
    test_magnitude_extraction()
    
    print(f"\nüéØ –§–ò–ù–ê–õ–¨–ù–ê–Ø –û–¶–ï–ù–ö–ê:")
    if accuracy >= 85:
        print("üèÜ –ü—Ä–µ–≤–æ—Å—Ö–æ–¥–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –°–∏—Å—Ç–µ–º–∞ –≥–æ—Ç–æ–≤–∞ –∫ –ø—Ä–æ–¥–∞–∫—à–µ–Ω—É")
    elif accuracy >= 75:
        print("üéâ –û—Ç–ª–∏—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç! –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ —É–ª—É—á—à–µ–Ω–∏–µ")
    elif accuracy >= 65:
        print("üëç –•–æ—Ä–æ—à–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å, –Ω–æ –µ—Å—Ç—å –º–µ—Å—Ç–æ –¥–ª—è –¥–æ—Ä–∞–±–æ—Ç–æ–∫")
    else:
        print("‚ö†Ô∏è –¢—Ä–µ–±—É—é—Ç—Å—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ —É–ª—É—á—à–µ–Ω–∏—è")
