
from functools import lru_cache
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch, requests, datetime as dt, re
from news_feed import fetch_news
from langdetect import detect
import warnings
from typing import Dict, List, Tuple, Optional
import statistics

# –ü–æ–¥–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –Ω–µ–∏—Å–ø–æ–ª—å–∑—É–µ–º—ã—Ö –≤–µ—Å–∞—Ö –º–æ–¥–µ–ª–∏
warnings.filterwarnings("ignore", category=UserWarning, module="transformers")

# –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–µ–π –¥–ª—è ensemble
MODEL_CONFIG = {
    "ru_models": [
        {
            "name": "seara/rubert-base-cased-russian-sentiment",
            "labels": ["NEGATIVE", "NEUTRAL", "POSITIVE"],
            "weight": 0.3,
            "description": "RuBERT —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π"
        },
        {
            "name": "blanchefort/rubert-base-cased-sentiment",
            "labels": ["NEUTRAL", "POSITIVE", "NEGATIVE"],
            "weight": 0.25,
            "description": "RuBERT –±–∞–∑–æ–≤—ã–π"
        },
        {
            "name": "nlptown/bert-base-multilingual-uncased-sentiment",
            "labels": ["1", "2", "3", "4", "5"],  # 1-2=negative, 3=neutral, 4-5=positive
            "weight": 0.45,
            "description": "–ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å (–ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–∞—è)"
        }
    ],
    "en_models": [
        {
            "name": "ProsusAI/finbert",
            "labels": ["positive", "negative", "neutral"],
            "weight": 0.6,
            "description": "FinBERT —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ –¥–ª—è —Ñ–∏–Ω–∞–Ω—Å–æ–≤"
        },
        {
            "name": "cardiffnlp/twitter-roberta-base-sentiment-latest",
            "labels": ["LABEL_0", "LABEL_1", "LABEL_2"],
            "weight": 0.4,
            "description": "Twitter RoBERTa"
        }
    ]
}

class FinancialSentimentEnsemble:
    """Ensemble –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏ –∏ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –ª–æ–≥–∏–∫–æ–π"""
    
    def __init__(self):
        # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–ª–æ–≤–∞—Ä–∏
        self.financial_terms = {
            'strong_positive': {
                'ru': ['—Ä–µ–∫–æ—Ä–¥', '–≤–∑–ª–µ—Ç', '—Å–∫–∞—á–æ–∫', '–±—É–º', '–ø—Ä–µ–≤–∑–æ—à', '–ø—Ä–æ—Ä—ã–≤', '—Ä–µ–∑–∫–∏–π —Ä–æ—Å—Ç'],
                'en': ['breakthrough', 'surge', 'soar', 'rally', 'boom', 'outperform', 'beat']
            },
            'moderate_positive': {
                'ru': ['–≤—ã—Ä–æ—Å–ª–∏', '—Ä–æ—Å—Ç', '—É–≤–µ–ª–∏—á', '–ø–æ–≤—ã—à', '—É–ª—É—á—à', '–ø—Ä–∏–±—ã–ª—å', '–¥–æ—Ö–æ–¥'],
                'en': ['improved', 'gained', 'rise', 'increase', 'profit', 'earnings', 'revenue']
            },
            'strong_negative': {
                'ru': ['–æ–±–≤–∞–ª', '–∫—Ä–∞—Ö', '–∫—Ä–∏–∑–∏—Å', '–∫–æ–ª–ª–∞–ø—Å', '–∫–∞—Ç–∞—Å—Ç—Ä–æ—Ñ', '–ø—Ä–æ–≤–∞–ª'],
                'en': ['plummet', 'crash', 'collapse', 'crisis', 'catastrophe', 'disaster']
            },
            'moderate_negative': {
                'ru': ['—É–ø–∞–ª–∏', '—Å–Ω–∏–∑–∏–ª', '–ø–∞–¥–µ–Ω–∏–µ', '—É–º–µ–Ω—å—à', '—É–±—ã—Ç', '–ø–æ—Ç–µ—Ä'],
                'en': ['declined', 'dropped', 'fell', 'loss', 'decrease', 'down']
            },
            'neutral_stable': {
                'ru': ['—Å—Ç–∞–±–∏–ª—å–Ω', '–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω', '–æ—Å—Ç–∞–ª', '–Ω–µ–∏–∑–º–µ–Ω–Ω'],
                'en': ['remained', 'stable', 'flat', 'unchanged', 'steady']
            }
        }
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —á–∏—Å–ª–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π
        self.number_pattern = r'(\d+(?:,\d+)?(?:\.\d+)?)\s*%'
        
        # –í–µ—Å–æ–≤—ã–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å–∏–≥–Ω–∞–ª–æ–≤
        self.weights = {
            'ml_ensemble': 0.5,      # –í–µ—Å ML-–∞–Ω—Å–∞–º–±–ª—è
            'financial_terms': 0.3,   # –í–µ—Å —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã—Ö —Ç–µ—Ä–º–∏–Ω–æ–≤
            'numeric_context': 0.2    # –í–µ—Å —á–∏—Å–ª–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        }
    
    def _normalize_multilingual_sentiment(self, label: str, model_name: str) -> str:
        """–ù–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –º–µ—Ç–∫–∏ —Ä–∞–∑–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π –∫ –µ–¥–∏–Ω–æ–º—É —Ñ–æ—Ä–º–∞—Ç—É"""
        if "nlptown" in model_name:
            # –ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω–∞—è –º–æ–¥–µ–ª—å: 1-2=negative, 3=neutral, 4-5=positive
            if label in ["1", "2"]:
                return "negative"
            elif label == "3":
                return "neutral"
            elif label in ["4", "5"]:
                return "positive"
        elif "finbert" in model_name.lower():
            # FinBERT —É–∂–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –º–µ—Ç–∫–∏
            return label.lower()
        elif "twitter" in model_name or "cardiff" in model_name:
            # Twitter RoBERTa
            mapping = {"LABEL_0": "negative", "LABEL_1": "neutral", "LABEL_2": "positive"}
            return mapping.get(label, "neutral")
        else:
            # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ RuBERT –º–æ–¥–µ–ª–∏
            label_upper = label.upper()
            if "NEGATIVE" in label_upper or "NEG" in label_upper:
                return "negative"
            elif "POSITIVE" in label_upper or "POS" in label_upper:
                return "positive"
            else:
                return "neutral"
    
    def _extract_financial_signals(self, text: str, lang: str) -> Dict[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã –∏–∑ —Ç–µ–∫—Å—Ç–∞"""
        text_lower = text.lower()
        signals = {'positive': 0, 'negative': 0, 'neutral': 0}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        for sentiment_type, terms_dict in self.financial_terms.items():
            if lang in terms_dict:
                for term in terms_dict[lang]:
                    if term in text_lower:
                        if 'positive' in sentiment_type:
                            weight = 2.0 if 'strong' in sentiment_type else 1.0
                            signals['positive'] += weight
                        elif 'negative' in sentiment_type:
                            weight = 2.0 if 'strong' in sentiment_type else 1.0
                            signals['negative'] += weight
                        else:  # neutral
                            signals['neutral'] += 1.0
        
        return signals
    
    def _extract_numeric_context(self, text: str) -> Dict[str, float]:
        """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —á–∏—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç (–ø—Ä–æ—Ü–µ–Ω—Ç—ã, —Å—É–º–º—ã)"""
        context = {'magnitude': 0, 'direction': 0}  # direction: +1=—Ä–æ—Å—Ç, -1=–ø–∞–¥–µ–Ω–∏–µ
        
        # –ò—â–µ–º –ø—Ä–æ—Ü–µ–Ω—Ç—ã
        numbers = re.findall(self.number_pattern, text.lower())
        if numbers:
            try:
                max_number = max(float(num.replace(',', '.')) for num in numbers)
                context['magnitude'] = max_number
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
                growth_words = ['–≤—ã—Ä–æ—Å–ª–∏', '—Ä–æ—Å—Ç', '—É–≤–µ–ª–∏—á', '–ø–æ–≤—ã—à', 'gained', 'rise', 'up']
                decline_words = ['—É–ø–∞–ª–∏', '—Å–Ω–∏–∑–∏–ª', '–ø–∞–¥–µ–Ω–∏–µ', '—É–º–µ–Ω—å—à', 'declined', 'dropped', 'down']
                
                text_lower = text.lower()
                if any(word in text_lower for word in growth_words):
                    context['direction'] = 1
                elif any(word in text_lower for word in decline_words):
                    context['direction'] = -1
                    
            except ValueError:
                pass
        
        return context
    
    def _ensemble_predict(self, text: str, models_config: List[Dict], lang: str = "ru") -> Dict[str, float]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç ensemble –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
        predictions = []
        total_weight = 0
        
        for model_info in models_config:
            try:
                # –ü—Ä–æ–±—É–µ–º –∑–∞–≥—Ä—É–∑–∏—Ç—å –∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –º–æ–¥–µ–ª—å
                tokenizer = AutoTokenizer.from_pretrained(model_info["name"])
                model = AutoModelForSequenceClassification.from_pretrained(model_info["name"])
                model.eval()
                
                inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
                with torch.no_grad():
                    logits = model(**inputs).logits
                
                probabilities = torch.softmax(logits, dim=-1)
                predicted_idx = logits.argmax().item()
                predicted_label = model_info["labels"][predicted_idx]
                confidence = probabilities[0][predicted_idx].item()
                
                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
                normalized_sentiment = self._normalize_multilingual_sentiment(predicted_label, model_info["name"])
                
                predictions.append({
                    'sentiment': normalized_sentiment,
                    'confidence': confidence,
                    'weight': model_info["weight"],
                    'model': model_info["description"]
                })
                total_weight += model_info["weight"]
                
                print(f"ü§ñ {model_info['description']}: {normalized_sentiment} (conf: {confidence:.3f})")
                
            except Exception as e:
                print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –º–æ–¥–µ–ª–∏ {model_info['name']}: {e}")
                continue
        
        # –í—ã—á–∏—Å–ª—è–µ–º –≤–∑–≤–µ—à–µ–Ω–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if not predictions:
            return {'sentiment': 'neutral', 'confidence': 0.0, 'details': []}
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        weighted_scores = {'positive': 0, 'negative': 0, 'neutral': 0}
        total_confidence = 0
        
        for pred in predictions:
            weight_norm = pred['weight'] / total_weight
            weighted_scores[pred['sentiment']] += weight_norm * pred['confidence']
            total_confidence += weight_norm * pred['confidence']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        final_sentiment = max(weighted_scores, key=weighted_scores.get)
        final_confidence = total_confidence / len(predictions)
        
        return {
            'sentiment': final_sentiment,
            'confidence': final_confidence,
            'details': predictions,
            'scores': weighted_scores
        }

# –ì–ª–æ–±–∞–ª—å–Ω—ã–π —ç–∫–∑–µ–º–ø–ª—è—Ä ensemble –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä–∞
_ensemble_analyzer = FinancialSentimentEnsemble()

@lru_cache(maxsize=10)
def _load_ensemble_models():
    """–ö—ç—à–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–µ–π –¥–ª—è ensemble"""
    print("üîÑ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è ensemble –º–æ–¥–µ–ª–µ–π...")
    return True  # –ú–æ–¥–µ–ª–∏ –∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ –≤ _ensemble_predict

def classify_ru_ensemble(text: str) -> str:
    """Ensemble –∞–Ω–∞–ª–∏–∑ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å –Ω–µ—Å–∫–æ–ª—å–∫–∏–º–∏ –º–æ–¥–µ–ª—è–º–∏"""
    print(f"üß† ENSEMBLE –ê–ù–ê–õ–ò–ó RU: '{text[:50]}...'")
    print("=" * 60)
    
    try:
        # 1. ML Ensemble
        ml_result = _ensemble_analyzer._ensemble_predict(
            text, MODEL_CONFIG["ru_models"], "ru"
        )
        print(f"ü§ñ ML Ensemble: {ml_result['sentiment']} (conf: {ml_result['confidence']:.3f})")
        
        # 2. –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        financial_signals = _ensemble_analyzer._extract_financial_signals(text, "ru")
        print(f"üí∞ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã: {financial_signals}")
        
        # 3. –ß–∏—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        numeric_context = _ensemble_analyzer._extract_numeric_context(text)
        print(f"üî¢ –ß–∏—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {numeric_context}")
        
        # 4. –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        final_score = 0
        
        # ML –≤–∫–ª–∞–¥
        ml_score = {'positive': 1, 'negative': -1, 'neutral': 0}.get(ml_result['sentiment'], 0)
        final_score += ml_score * _ensemble_analyzer.weights['ml_ensemble'] * ml_result['confidence']
        
        # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        if financial_signals['positive'] > financial_signals['negative']:
            term_score = min(1.0, financial_signals['positive'] / 3.0)
        elif financial_signals['negative'] > financial_signals['positive']:
            term_score = -min(1.0, financial_signals['negative'] / 3.0)
        else:
            term_score = 0
        
        final_score += term_score * _ensemble_analyzer.weights['financial_terms']
        
        # –ß–∏—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        if numeric_context['magnitude'] > 0:
            magnitude_weight = min(1.0, numeric_context['magnitude'] / 10.0)  # –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ 1.0
            numeric_score = numeric_context['direction'] * magnitude_weight
            final_score += numeric_score * _ensemble_analyzer.weights['numeric_context']
            print(f"üìä –ß–∏—Å–ª–æ–≤–æ–π –≤–∫–ª–∞–¥: {numeric_score:.3f} (–Ω–∞–ø—Ä–∞–≤–ª–µ–Ω–∏–µ: {numeric_context['direction']}, –≤–µ–ª–∏—á–∏–Ω–∞: {numeric_context['magnitude']}%)")
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if final_score > 0.3:
            result = 'positive'
        elif final_score < -0.3:
            result = 'negative'
        else:
            result = 'neutral'
        
        print(f"üéØ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä: {final_score:.3f} ‚Üí {result}")
        print("=" * 60)
        
        return result
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ ensemble –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return "neutral"

def classify_en_ensemble(text: str) -> str:
    """Ensemble –∞–Ω–∞–ª–∏–∑ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞ —Å FinBERT –∏ RoBERTa"""
    print(f"üß† ENSEMBLE –ê–ù–ê–õ–ò–ó EN: '{text[:50]}...'")
    print("=" * 60)
    
    try:
        # ML Ensemble –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ
        ml_result = _ensemble_analyzer._ensemble_predict(
            text, MODEL_CONFIG["en_models"], "en"
        )
        print(f"ü§ñ ML Ensemble: {ml_result['sentiment']} (conf: {ml_result['confidence']:.3f})")
        
        # –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Ç–µ—Ä–º–∏–Ω—ã
        financial_signals = _ensemble_analyzer._extract_financial_signals(text, "en")
        print(f"üí∞ –§–∏–Ω–∞–Ω—Å–æ–≤—ã–µ —Å–∏–≥–Ω–∞–ª—ã: {financial_signals}")
        
        # –ß–∏—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç
        numeric_context = _ensemble_analyzer._extract_numeric_context(text)
        print(f"üî¢ –ß–∏—Å–ª–æ–≤–æ–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: {numeric_context}")
        
        # –î–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ –±–æ–ª—å—à–µ –¥–æ–≤–µ—Ä—è–µ–º ML (–æ—Å–æ–±–µ–Ω–Ω–æ FinBERT)
        weights_en = {'ml_ensemble': 0.7, 'financial_terms': 0.2, 'numeric_context': 0.1}
        
        final_score = 0
        
        # ML –≤–∫–ª–∞–¥ (–±–æ–ª—å—à–∏–π –≤–µ—Å –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ)
        ml_score = {'positive': 1, 'negative': -1, 'neutral': 0}.get(ml_result['sentiment'], 0)
        final_score += ml_score * weights_en['ml_ensemble'] * ml_result['confidence']
        
        # –û—Å—Ç–∞–ª—å–Ω–∞—è –ª–æ–≥–∏–∫–∞ –∞–Ω–∞–ª–æ–≥–∏—á–Ω–∞ —Ä—É—Å—Å–∫–æ–º—É
        if financial_signals['positive'] > financial_signals['negative']:
            term_score = min(1.0, financial_signals['positive'] / 3.0)
        elif financial_signals['negative'] > financial_signals['positive']:
            term_score = -min(1.0, financial_signals['negative'] / 3.0)
        else:
            term_score = 0
        
        final_score += term_score * weights_en['financial_terms']
        
        if numeric_context['magnitude'] > 0:
            magnitude_weight = min(1.0, numeric_context['magnitude'] / 10.0)
            numeric_score = numeric_context['direction'] * magnitude_weight
            final_score += numeric_score * weights_en['numeric_context']
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        if final_score > 0.2:  # –ú–µ–Ω—å—à–∏–π –ø–æ—Ä–æ–≥ –¥–ª—è –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ
            result = 'positive'
        elif final_score < -0.2:
            result = 'negative'
        else:
            result = 'neutral'
        
        print(f"üéØ –§–∏–Ω–∞–ª—å–Ω—ã–π —Å–∫–æ—Ä: {final_score:.3f} ‚Üí {result}")
        print("=" * 60)
        
        return result
        
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ ensemble –∞–Ω–∞–ª–∏–∑–∞: {e}")
        return "neutral"

# –û—Å–Ω–æ–≤–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ —Å ensemble –ø–æ–¥—Ö–æ–¥–æ–º
def classify_ru(text: str) -> str:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ —Ä—É—Å—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    return classify_ru_ensemble(text)

def classify_en(text: str) -> str:
    """–ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∞–Ω–≥–ª–∏–π—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞"""
    return classify_en_ensemble(text)

def classify_multi(text: str) -> str:
    """–ú—É–ª—å—Ç–∏—è–∑—ã—á–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è —Å ensemble"""
    try:
        lang = detect(text[:200])
        if lang == "ru":
            return classify_ru_ensemble(text)
        else:
            return classify_en_ensemble(text)
    except Exception as e:
        print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —è–∑—ã–∫–∞: {e}")
        return classify_en_ensemble(text)

def analyze_sentiment_trend(texts: List[str]) -> Dict[str, float]:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–µ–Ω–¥ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∏—è –ø–æ –º–Ω–æ–∂–µ—Å—Ç–≤—É —Ç–µ–∫—Å—Ç–æ–≤"""
    if not texts:
        return {'trend': 0.0, 'confidence': 0.0, 'count': 0}
    
    sentiments = []
    for text in texts:
        sentiment = classify_multi(text)
        score = {'positive': 1, 'negative': -1, 'neutral': 0}.get(sentiment, 0)
        sentiments.append(score)
    
    avg_sentiment = sum(sentiments) / len(sentiments)
    consistency = 1.0 - (len(set(sentiments)) - 1) / 2.0
    
    return {
        'trend': avg_sentiment,
        'confidence': consistency,
        'count': len(texts),
        'distribution': {
            'positive': sentiments.count(1),
            'negative': sentiments.count(-1),
            'neutral': sentiments.count(0)
        }
    }

# –û–±—Ä–∞—Ç–Ω–∞—è —Å–æ–≤–º–µ—Å—Ç–∏–º–æ—Å—Ç—å
def classify(text: str) -> str:
    return classify_ru(text)

# RSS-–≥—Ä–∞–±–±–µ—Ä (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π)
RSS_FEEDS = [
    "https://tass.ru/rss/v2.xml",
    "https://rssexport.rbc.ru/rbcnews/news/30/full.rss",
]

def latest_news_ru(ticker: str, hours: int = 24) -> list[str]:
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Ä—É—Å—Å–∫–∏—Ö –Ω–æ–≤–æ—Å—Ç–µ–π –∏–∑ RSS"""
    cutoff = dt.datetime.utcnow() - dt.timedelta(hours=hours)
    found = []
    for url in RSS_FEEDS:
        try:
            xml = requests.get(url, timeout=5).text
            for it in xml.split("<item>")[1:]:
                title = it.split("<title>")[1].split("</title>")[0]
                pub   = it.split("<pubDate>")[1].split("</pubDate>")[0]
                dt_pub = dt.datetime.strptime(pub[:-6], "%a, %d %b %Y %H:%M:%S")
                if dt_pub > cutoff and ticker.lower() in title.lower():
                    found.append(title)
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ RSS {url}: {e}")
            continue
    return found

def latest_news(ticker: str, hours: int = 24) -> list[str]:
    return latest_news_ru(ticker, hours)
