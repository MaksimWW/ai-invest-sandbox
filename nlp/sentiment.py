from functools import lru_cache
from transformers import AutoTokenizer, AutoModelForSequenceClassification, pipeline
import torch, requests, datetime as dt, re
from news_feed import fetch_news
from langdetect import detect
import warnings
from typing import Dict, List, Tuple, Optional
import statistics

# ÐŸÐ¾Ð´Ð°Ð²Ð»ÑÐµÐ¼ Ð¿Ñ€ÐµÐ´ÑƒÐ¿Ñ€ÐµÐ¶Ð´ÐµÐ½Ð¸Ñ Ð¾ Ð½ÐµÐ¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ñ… Ð²ÐµÑÐ°Ñ… Ð¼Ð¾Ð´ÐµÐ»Ð¸
warnings.filterwarnings("ignore", category=UserWarning, module="transformers")

# ÐšÐ¾Ð½Ñ„Ð¸Ð³ÑƒÑ€Ð°Ñ†Ð¸Ñ Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ ensemble
MODEL_CONFIG = {
    "ru_models": [
        {
            "name": "seara/rubert-base-cased-russian-sentiment",
            "labels": ["NEGATIVE", "NEUTRAL", "POSITIVE"],
            "weight": 0.3,
            "description": "RuBERT ÑÐ¿ÐµÑ†Ð¸Ð°Ð»Ð¸Ð·Ð¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ñ‹Ð¹"
        },
        {
            "name": "blanchefort/rubert-base-cased-sentiment",
            "labels": ["NEUTRAL", "POSITIVE", "NEGATIVE"],
            "weight": 0.25,
            "description": "RuBERT Ð±Ð°Ð·Ð¾Ð²Ñ‹Ð¹"
        },
        {
            "name": "nlptown/bert-base-multilingual-uncased-sentiment",
            "labels": ["1", "2", "3", "4", "5"],  # 1-2=negative, 3=neutral, 4-5=positive
            "weight": 0.45,
            "description": "ÐœÑƒÐ»ÑŒÑ‚Ð¸ÑÐ·Ñ‹Ñ‡Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ (Ð¿Ñ€Ð¸Ð¾Ñ€Ð¸Ñ‚ÐµÑ‚Ð½Ð°Ñ)"
        }
    ],
    "en_models": [
        {
            "name": "ProsusAI/finbert",
            "labels": ["positive", "negative", "neutral"],
            "weight": 0.6,
            "description": "FinBERT ÑÐ¿ÐµÑ†Ð¸Ð°Ð»ÑŒÐ½Ð¾ Ð´Ð»Ñ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²"
        },
        {
            "name": "cardiffnlp/twitter-roberta-base-sentiment-latest",
            "labels": ["LABEL_0", "LABEL_1", "LABEL_2"],
            "weight": 0.4,
            "description": "Twitter RoBERTa"
        }
    ]
}

class FinancialSentimentEnsemble:
    """Ensemble Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€ Ñ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸ Ð¸ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ð¾Ð¹ Ð»Ð¾Ð³Ð¸ÐºÐ¾Ð¹"""

    def __init__(self):
        # Ð¤Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ ÑÐ»Ð¾Ð²Ð°Ñ€Ð¸
        self.financial_terms = {
            'strong_positive': {
                'ru': ['Ñ€ÐµÐºÐ¾Ñ€Ð´', 'Ð²Ð·Ð»ÐµÑ‚', 'ÑÐºÐ°Ñ‡Ð¾Ðº', 'Ð±ÑƒÐ¼', 'Ð¿Ñ€ÐµÐ²Ð·Ð¾Ñˆ', 'Ð¿Ñ€Ð¾Ñ€Ñ‹Ð²', 'Ñ€ÐµÐ·ÐºÐ¸Ð¹ Ñ€Ð¾ÑÑ‚'],
                'en': ['breakthrough', 'surge', 'soar', 'rally', 'boom', 'outperform', 'beat']
            },
            'moderate_positive': {
                'ru': ['Ð²Ñ‹Ñ€Ð¾ÑÐ»Ð¸', 'Ñ€Ð¾ÑÑ‚', 'ÑƒÐ²ÐµÐ»Ð¸Ñ‡', 'Ð¿Ð¾Ð²Ñ‹Ñˆ', 'ÑƒÐ»ÑƒÑ‡Ñˆ', 'Ð¿Ñ€Ð¸Ð±Ñ‹Ð»ÑŒ', 'Ð´Ð¾Ñ…Ð¾Ð´'],
                'en': ['improved', 'gained', 'rise', 'increase', 'profit', 'earnings', 'revenue']
            },
            'strong_negative': {
                'ru': ['Ð¾Ð±Ð²Ð°Ð»', 'ÐºÑ€Ð°Ñ…', 'ÐºÑ€Ð¸Ð·Ð¸Ñ', 'ÐºÐ¾Ð»Ð»Ð°Ð¿Ñ', 'ÐºÐ°Ñ‚Ð°ÑÑ‚Ñ€Ð¾Ñ„', 'Ð¿Ñ€Ð¾Ð²Ð°Ð»'],
                'en': ['plummet', 'crash', 'collapse', 'crisis', 'catastrophe', 'disaster']
            },
            'moderate_negative': {
                'ru': ['ÑƒÐ¿Ð°Ð»Ð¸', 'ÑÐ½Ð¸Ð·Ð¸Ð»', 'Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ', 'ÑƒÐ¼ÐµÐ½ÑŒÑˆ', 'ÑƒÐ±Ñ‹Ñ‚', 'Ð¿Ð¾Ñ‚ÐµÑ€'],
                'en': ['declined', 'dropped', 'fell', 'loss', 'decrease', 'down']
            },
            'neutral_stable': {
                'ru': ['ÑÑ‚Ð°Ð±Ð¸Ð»ÑŒÐ½', 'Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½', 'Ð¾ÑÑ‚Ð°Ð»', 'Ð½ÐµÐ¸Ð·Ð¼ÐµÐ½Ð½'],
                'en': ['remained', 'stable', 'flat', 'unchanged', 'steady']
            }
        }

        # ÐŸÐ°Ñ‚Ñ‚ÐµÑ€Ð½Ñ‹ Ð´Ð»Ñ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ñ‹Ñ… Ð·Ð½Ð°Ñ‡ÐµÐ½Ð¸Ð¹
        self.number_pattern = r'(\d+(?:,\d+)?(?:\.\d+)?)\s*%'

        # Ð’ÐµÑÐ¾Ð²Ñ‹Ðµ ÐºÐ¾ÑÑ„Ñ„Ð¸Ñ†Ð¸ÐµÐ½Ñ‚Ñ‹ Ð´Ð»Ñ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð¸ÑÑ‚Ð¾Ñ‡Ð½Ð¸ÐºÐ¾Ð² ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²
        self.weights = {
            'ml_ensemble': 0.5,      # Ð’ÐµÑ ML-Ð°Ð½ÑÐ°Ð¼Ð±Ð»Ñ
            'financial_terms': 0.3,   # Ð’ÐµÑ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ñ… Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð²
            'numeric_context': 0.2    # Ð’ÐµÑ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð³Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ð°
        }

    def _normalize_multilingual_sentiment(self, label: str, model_name: str) -> str:
        """ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÑ‚ Ð¼ÐµÑ‚ÐºÐ¸ Ñ€Ð°Ð·Ð½Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ðº ÐµÐ´Ð¸Ð½Ð¾Ð¼Ñƒ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚Ñƒ"""
        if "nlptown" in model_name:
            # ÐœÑƒÐ»ÑŒÑ‚Ð¸ÑÐ·Ñ‹Ñ‡Ð½Ð°Ñ Ð¼Ð¾Ð´ÐµÐ»ÑŒ: 1-2=negative, 3=neutral, 4-5=positive
            if label in ["1", "2"]:
                return "negative"
            elif label == "3":
                return "neutral"
            elif label in ["4", "5"]:
                return "positive"
        elif "finbert" in model_name.lower():
            # FinBERT ÑƒÐ¶Ðµ Ð²Ð¾Ð·Ð²Ñ€Ð°Ñ‰Ð°ÐµÑ‚ Ð¿Ñ€Ð°Ð²Ð¸Ð»ÑŒÐ½Ñ‹Ðµ Ð¼ÐµÑ‚ÐºÐ¸
            return label.lower()
        elif "twitter" in model_name or "cardiff" in model_name:
            # Twitter RoBERTa
            mapping = {"LABEL_0": "negative", "LABEL_1": "neutral", "LABEL_2": "positive"}
            return mapping.get(label, "neutral")
        else:
            # Ð¡Ñ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ðµ RuBERT Ð¼Ð¾Ð´ÐµÐ»Ð¸
            label_upper = label.upper()
            if "NEGATIVE" in label_upper or "NEG" in label_upper:
                return "negative"
            elif "POSITIVE" in label_upper or "POS" in label_upper:
                return "positive"
            else:
                return "neutral"

    def _extract_financial_signals(self, text: str, lang: str) -> Dict[str, float]:
        """Ð˜Ð·Ð²Ð»ÐµÐºÐ°ÐµÑ‚ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ ÑÐ¸Ð³Ð½Ð°Ð»Ñ‹ Ð¸Ð· Ñ‚ÐµÐºÑÑ‚Ð°"""
        text_lower = text.lower()
        signals = {'positive': 0, 'negative': 0, 'neutral': 0}

        # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ðµ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ñ‹
        for sentiment_type, terms_dict in self.financial_terms.items():
            if lang in terms_dict:
                for term in terms_dict[lang]:
                    if term in text_lower:
                        if 'positive' in sentiment_type:
                            weight = 2.0 if 'strong' in sentiment_type else 1.0
                            signals['positive'] += weight
                        elif 'negative' in sentiment_type:
                            weight = 2.0 if 'strong' in sentiment_type else 1.0
                            signals['negative'] += weight
                        else:  # neutral
                            signals['neutral'] += 1.0

        return signals

    def _extract_numeric_context(self, text: str) -> Dict[str, float]:
        """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ‡Ð¸ÑÐ»Ð¾Ð²Ð¾Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚ (Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ñ‹, ÑÑƒÐ¼Ð¼Ñ‹)"""
        context = {'magnitude': 0, 'direction': 0}  # direction: +1=Ñ€Ð¾ÑÑ‚, -1=Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ

        # Ð˜Ñ‰ÐµÐ¼ Ð¿Ñ€Ð¾Ñ†ÐµÐ½Ñ‚Ñ‹
        numbers = re.findall(self.number_pattern, text.lower())
        if numbers:
            try:
                max_number = max(float(num.replace(',', '.')) for num in numbers)
                context['magnitude'] = max_number

                # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ð½Ð°Ð¿Ñ€Ð°Ð²Ð»ÐµÐ½Ð¸Ðµ Ð¿Ð¾ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚Ñƒ
                growth_words = ['Ð²Ñ‹Ñ€Ð¾ÑÐ»Ð¸', 'Ñ€Ð¾ÑÑ‚', 'ÑƒÐ²ÐµÐ»Ð¸Ñ‡', 'Ð¿Ð¾Ð²Ñ‹Ñˆ', 'gained', 'rise', 'up']
                decline_words = ['ÑƒÐ¿Ð°Ð»Ð¸', 'ÑÐ½Ð¸Ð·Ð¸Ð»', 'Ð¿Ð°Ð´ÐµÐ½Ð¸Ðµ', 'ÑƒÐ¼ÐµÐ½ÑŒÑˆ', 'declined', 'dropped', 'down']

                text_lower = text.lower()
                if any(word in text_lower for word in growth_words):
                    context['direction'] = 1
                elif any(word in text_lower for word in decline_words):
                    context['direction'] = -1

            except ValueError:
                pass

        return context

    def _ensemble_predict(self, text: str, models_config: List[Dict], lang: str = "ru") -> Dict[str, float]:
        """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ ensemble Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸"""
        predictions = []
        total_weight = 0

        for model_info in models_config:
            try:
                # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
                tokenizer = AutoTokenizer.from_pretrained(model_info["name"])
                model = AutoModelForSequenceClassification.from_pretrained(model_info["name"])
                model.eval()

                inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
                with torch.no_grad():
                    logits = model(**inputs).logits

                probabilities = torch.softmax(logits, dim=-1)
                predicted_idx = logits.argmax().item()
                predicted_label = model_info["labels"][predicted_idx]
                confidence = probabilities[0][predicted_idx].item()

                # ÐÐ¾Ñ€Ð¼Ð°Ð»Ð¸Ð·ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
                normalized_sentiment = self._normalize_multilingual_sentiment(predicted_label, model_info["name"])

                predictions.append({
                    'sentiment': normalized_sentiment,
                    'confidence': confidence,
                    'weight': model_info["weight"],
                    'model': model_info["description"]
                })
                total_weight += model_info["weight"]

                print(f"ðŸ¤– {model_info['description']}: {normalized_sentiment} (conf: {confidence:.3f})")

            except Exception as e:
                print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»Ð¸ {model_info['name']}: {e}")
                continue

        # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        if not predictions:
            return {'sentiment': 'neutral', 'confidence': 0.0, 'details': []}

        # ÐÐ³Ñ€ÐµÐ³Ð¸Ñ€ÑƒÐµÐ¼ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚Ñ‹
        weighted_scores = {'positive': 0, 'negative': 0, 'neutral': 0}
        total_confidence = 0

        for pred in predictions:
            weight_norm = pred['weight'] / total_weight
            weighted_scores[pred['sentiment']] += weight_norm * pred['confidence']
            total_confidence += weight_norm * pred['confidence']

        # ÐžÐ¿Ñ€ÐµÐ´ÐµÐ»ÑÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð»ÑŒÐ½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
        final_sentiment = max(weighted_scores, key=weighted_scores.get)
        final_confidence = total_confidence / len(predictions)

        return {
            'sentiment': final_sentiment,
            'confidence': final_confidence,
            'details': predictions,
            'scores': weighted_scores
        }

# Ð“Ð»Ð¾Ð±Ð°Ð»ÑŒÐ½Ñ‹Ð¹ ÑÐºÐ·ÐµÐ¼Ð¿Ð»ÑÑ€ ensemble Ð°Ð½Ð°Ð»Ð¸Ð·Ð°Ñ‚Ð¾Ñ€Ð°
_ensemble_analyzer = FinancialSentimentEnsemble()

@lru_cache(maxsize=10)
def _load_ensemble_models():
    """ÐšÑÑˆÐ¸Ñ€Ð¾Ð²Ð°Ð½Ð½Ð°Ñ Ð·Ð°Ð³Ñ€ÑƒÐ·ÐºÐ° Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ ensemble"""
    print("ðŸ”„ Ð˜Ð½Ð¸Ñ†Ð¸Ð°Ð»Ð¸Ð·Ð°Ñ†Ð¸Ñ ensemble Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹...")
    return True  # ÐœÐ¾Ð´ÐµÐ»Ð¸ Ð·Ð°Ð³Ñ€ÑƒÐ¶Ð°ÑŽÑ‚ÑÑ Ð´Ð¸Ð½Ð°Ð¼Ð¸Ñ‡ÐµÑÐºÐ¸ Ð² _ensemble_predict

@lru_cache(maxsize=256)
def classify_ru_ensemble(text: str) -> str:
    """ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÑ‚ Ñ€ÑƒÑÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ensemble Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹"""
    return _ensemble_classify(text, MODEL_CONFIG["ru_models"])

@lru_cache(maxsize=256)  
def classify_en_ensemble(text: str) -> str:
    """ÐšÐ»Ð°ÑÑÐ¸Ñ„Ð¸Ñ†Ð¸Ñ€ÑƒÐµÑ‚ Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¸Ð¹ Ñ‚ÐµÐºÑÑ‚ Ñ Ð¿Ð¾Ð¼Ð¾Ñ‰ÑŒÑŽ ensemble Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹"""
    return _ensemble_classify(text, MODEL_CONFIG["en_models"])

def _ensemble_classify(text: str, models_config: list) -> str:
    """Ð’Ñ‹Ð¿Ð¾Ð»Ð½ÑÐµÑ‚ ensemble Ð¿Ñ€ÐµÐ´ÑÐºÐ°Ð·Ð°Ð½Ð¸Ðµ Ñ Ð½ÐµÑÐºÐ¾Ð»ÑŒÐºÐ¸Ð¼Ð¸ Ð¼Ð¾Ð´ÐµÐ»ÑÐ¼Ð¸"""
    predictions = []
    total_weight = 0

    # ÐžÐ³Ñ€Ð°Ð½Ð¸Ñ‡Ð¸Ð²Ð°ÐµÐ¼ ÐºÐ¾Ð»Ð¸Ñ‡ÐµÑÑ‚Ð²Ð¾ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼Ñ‹Ñ… Ð¼Ð¾Ð´ÐµÐ»ÐµÐ¹ Ð´Ð»Ñ ÑÐ½Ð¸Ð¶ÐµÐ½Ð¸Ñ Ð½Ð°Ð³Ñ€ÑƒÐ·ÐºÐ¸
    active_models = models_config[:2]  # Ð˜ÑÐ¿Ð¾Ð»ÑŒÐ·ÑƒÐµÐ¼ Ñ‚Ð¾Ð»ÑŒÐºÐ¾ 2 Ð¼Ð¾Ð´ÐµÐ»Ð¸

    for model_info in active_models:
        try:
            # ÐŸÑ€Ð¾Ð±ÑƒÐµÐ¼ Ð·Ð°Ð³Ñ€ÑƒÐ·Ð¸Ñ‚ÑŒ Ð¸ Ð¸ÑÐ¿Ð¾Ð»ÑŒÐ·Ð¾Ð²Ð°Ñ‚ÑŒ Ð¼Ð¾Ð´ÐµÐ»ÑŒ
            tokenizer = AutoTokenizer.from_pretrained(model_info["name"])
            model = AutoModelForSequenceClassification.from_pretrained(model_info["name"])
            model.eval()

            inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=512)
            with torch.no_grad():
                logits = model(**inputs).logits

            probabilities = torch.softmax(logits, dim=-1)
            predicted_idx = logits.argmax().item()
            predicted_label = model_info["labels"][predicted_idx]
            confidence = probabilities[0][predicted_idx].item()

            # ÐšÐ¾Ð½Ð²ÐµÑ€Ñ‚Ð¸Ñ€ÑƒÐµÐ¼ Ð² ÑÑ‚Ð°Ð½Ð´Ð°Ñ€Ñ‚Ð½Ñ‹Ð¹ Ñ„Ð¾Ñ€Ð¼Ð°Ñ‚
            if predicted_label.upper() in ["POSITIVE", "POS"]:
                sentiment_score = 1.0
            elif predicted_label.upper() in ["NEGATIVE", "NEG"]:
                sentiment_score = -1.0
            else:
                sentiment_score = 0.0

            predictions.append(sentiment_score * confidence * model_info["weight"])
            total_weight += model_info["weight"]

        except Exception as e:
            print(f"âš ï¸ ÐœÐ¾Ð´ÐµÐ»ÑŒ {model_info['name'][:20]}... Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿Ð½Ð°")
            continue

    if not predictions:
        return "neutral"

    # Ð’Ñ‹Ñ‡Ð¸ÑÐ»ÑÐµÐ¼ Ð²Ð·Ð²ÐµÑˆÐµÐ½Ð½Ñ‹Ð¹ Ñ€ÐµÐ·ÑƒÐ»ÑŒÑ‚Ð°Ñ‚
    ensemble_score = sum(predictions) / total_weight if total_weight > 0 else 0

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ð¹ ÐºÐ¾Ð½Ñ‚ÐµÐºÑÑ‚
    financial_signals = _extract_financial_signals(text)

    # Ð˜Ñ‚Ð¾Ð³Ð¾Ð²Ñ‹Ð¹ ÑÐºÐ¾Ñ€ Ñ ÑƒÑ‡ÐµÑ‚Ð¾Ð¼ Ñ„Ð¸Ð½Ð°Ð½ÑÐ¾Ð²Ñ‹Ñ… ÑÐ¸Ð³Ð½Ð°Ð»Ð¾Ð²
    final_score = (
        ensemble_score * 0.8 +
        (financial_signals['positive'] - financial_signals['negative']) * 0.2
    )

    if final_score > 0.1:
        result = "positive"
    elif final_score < -0.1:
        result = "negative"
    else:
        result = "neutral"

    return result

# ÐžÑÐ½Ð¾Ð²Ð½Ñ‹Ðµ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ð¸ Ñ ensemble Ð¿Ð¾Ð´Ñ…Ð¾Ð´Ð¾Ð¼
def classify_ru(text: str) -> str:
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ñ€ÑƒÑÑÐºÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°"""
    return classify_ru_ensemble(text)

def classify_en(text: str) -> str:
    """Ð“Ð»Ð°Ð²Ð½Ð°Ñ Ñ„ÑƒÐ½ÐºÑ†Ð¸Ñ Ð´Ð»Ñ Ð°Ð½Ð°Ð»Ð¸Ð·Ð° Ð°Ð½Ð³Ð»Ð¸Ð¹ÑÐºÐ¾Ð³Ð¾ Ñ‚ÐµÐºÑÑ‚Ð°"""
    return classify_en_ensemble(text)

def classify_multi(text: str) -> str:
    """ÐœÑƒÐ»ÑŒÑ‚Ð¸ÑÐ·Ñ‹Ñ‡Ð½Ñ‹Ð¹ Ð°Ð½Ð°Ð»Ð¸Ð· Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ñ ensemble"""
    try:
        lang = detect(text[:200])
        if lang == "ru":
            return classify_ru_ensemble(text)
        else:
            return classify_en_ensemble(text)
    except Exception as e:
        print(f"âš ï¸ ÐžÑˆÐ¸Ð±ÐºÐ° Ð¾Ð¿Ñ€ÐµÐ´ÐµÐ»ÐµÐ½Ð¸Ñ ÑÐ·Ñ‹ÐºÐ°: {e}")
        return classify_en_ensemble(text)

def analyze_sentiment_trend(texts: List[str]) -> Dict[str, float]:
    """ÐÐ½Ð°Ð»Ð¸Ð·Ð¸Ñ€ÑƒÐµÑ‚ Ñ‚Ñ€ÐµÐ½Ð´ Ð½Ð°ÑÑ‚Ñ€Ð¾ÐµÐ½Ð¸Ñ Ð¿Ð¾ Ð¼Ð½Ð¾Ð¶ÐµÑÑ‚Ð²Ñƒ Ñ‚ÐµÐºÑÑ‚Ð¾Ð²"""
    if not texts:
        return {'trend': 0.0, 'confidence': 0.0, 'count': 0}

    sentiments = []
    for text in texts:
        sentiment = classify_multi(text)
        score = {'positive': 1, 'negative': -1, 'neutral': 0}.get(sentiment, 0)
        sentiments.append(score)

    avg_sentiment = sum(sentiments) / len(sentiments)
    consistency = 1.0 - (len(set(sentiments)) - 1) / 2.0

    return {
        'trend': avg_sentiment,
        'confidence': consistency,
        'count': len(texts),
        'distribution': {
            'positive': sentiments.count(1),
            'negative': sentiments.count(-1),
            'neutral': sentiments.count(0)
        }
    }

# ÐžÐ±Ñ€Ð°Ñ‚Ð½Ð°Ñ ÑÐ¾Ð²Ð¼ÐµÑÑ‚Ð¸Ð¼Ð¾ÑÑ‚ÑŒ
def classify(text: str) -> str:
    return classify_ru(text)

# RSS-Ð³Ñ€Ð°Ð±Ð±ÐµÑ€ (Ð±ÐµÐ· Ð¸Ð·Ð¼ÐµÐ½ÐµÐ½Ð¸Ð¹)
RSS_FEEDS = [
    "https://www.rbc.ru/rss/finances.rss",
    "https://www.vedomosti.ru/rss/news",
    "https://lenta.ru/rss/finances",
    "https://ria.ru/export/rss2/economy/index.xml",
    "https://www.interfax.ru/rss.asp?sec=business",
    "https://www.kommersant.ru/RSS/main.xml",
    "https://quote.rbc.ru/news/rss/",
]

def latest_news_ru(ticker: str, hours: int = 24) -> list[str]:
    """ÐŸÐ¾Ð»ÑƒÑ‡Ð¸Ñ‚ÑŒ Ð¿Ð¾ÑÐ»ÐµÐ´Ð½Ð¸Ðµ Ñ€ÑƒÑÑÐºÐ¸Ðµ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¿Ð¾ Ñ‚Ð¸ÐºÐµÑ€Ñƒ"""
    cutoff = dt.datetime.now() - dt.timedelta(hours=hours)
    all_news = []

    # Ð”Ð¾Ð±Ð°Ð²Ð»ÑÐµÐ¼ Ð°Ð»ÑŒÑ‚ÐµÑ€Ð½Ð°Ñ‚Ð¸Ð²Ð½Ñ‹Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ Ð´Ð»Ñ Ð¿Ð¾Ð¸ÑÐºÐ°
    search_terms = [ticker.upper()]

    # ÐœÐ°Ð¿Ð¿Ð¸Ð½Ð³ Ñ‚Ð¸ÐºÐµÑ€Ð¾Ð² Ð½Ð° Ñ€ÑƒÑÑÐºÐ¸Ðµ Ð½Ð°Ð·Ð²Ð°Ð½Ð¸Ñ
    ticker_names = {
        "YNDX": ["Ð¯Ð½Ð´ÐµÐºÑ", "Yandex"],
        "SBER": ["Ð¡Ð±ÐµÑ€Ð±Ð°Ð½Ðº", "Ð¡Ð±ÐµÑ€"],
        "GAZP": ["Ð“Ð°Ð·Ð¿Ñ€Ð¾Ð¼"],
        "LKOH": ["Ð›ÑƒÐºÐ¾Ð¹Ð»", "Ð›Ð£ÐšÐžÐ™Ð›"],
        "NVTK": ["ÐÐ¾Ð²Ð°Ñ‚ÑÐº", "ÐÐžÐ’ÐÐ¢Ð­Ðš"],
        "FXIT": ["Fix Price", "Ð¤Ð¸ÐºÑ ÐŸÑ€Ð°Ð¹Ñ"]
    }

    if ticker in ticker_names:
        search_terms.extend(ticker_names[ticker])

    print(f"ðŸ” Ð˜Ñ‰ÐµÐ¼ Ð½Ð¾Ð²Ð¾ÑÑ‚Ð¸ Ð¿Ð¾ Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð°Ð¼: {search_terms}")

    for rss_url in RSS_FEEDS:
        try:
            response = requests.get(rss_url, timeout=10)
            response.raise_for_status()

            # ÐŸÐ°Ñ€ÑÐ¸Ð¼ XML
            import xml.etree.ElementTree as ET
            root = ET.fromstring(response.content)

            # ÐÐ°Ñ…Ð¾Ð´Ð¸Ð¼ Ð²ÑÐµ ÑÐ»ÐµÐ¼ÐµÐ½Ñ‚Ñ‹ item
            items = root.findall('.//item')

            for item in items:
                title_elem = item.find('title')
                if title_elem is not None and title_elem.text:
                    title = title_elem.text.strip()

                    # ÐŸÑ€Ð¾Ð²ÐµÑ€ÑÐµÐ¼, ÑÐ¾Ð´ÐµÑ€Ð¶Ð¸Ñ‚ Ð»Ð¸ Ð·Ð°Ð³Ð¾Ð»Ð¾Ð²Ð¾Ðº Ð»ÑŽÐ±Ð¾Ð¹ Ð¸Ð· Ð¿Ð¾Ð¸ÑÐºÐ¾Ð²Ñ‹Ñ… Ñ‚ÐµÑ€Ð¼Ð¸Ð½Ð¾Ð²
                    title_upper = title.upper()
                    if any(term.upper() in title_upper for term in search_terms):
                        all_news.append(title)
                        print(f"âœ… ÐÐ°Ð¹Ð´ÐµÐ½Ð° Ð½Ð¾Ð²Ð¾ÑÑ‚ÑŒ: {title[:80]}...")

        except Exception as e:
            print(f"âš ï¸ RSS Ð½ÐµÐ´Ð¾ÑÑ‚ÑƒÐ¿ÐµÐ½: {rss_url[:50]}...")
            continue

    print(f"ðŸ“Š Ð˜Ñ‚Ð¾Ð³Ð¾ Ð½Ð°Ð¹Ð´ÐµÐ½Ð¾ Ð½Ð¾Ð²Ð¾ÑÑ‚ÐµÐ¹ Ð´Ð»Ñ {ticker}: {len(all_news)}")
    return all_news

def latest_news(ticker: str, hours: int = 24) -> list[str]:
    return latest_news_ru(ticker, hours)